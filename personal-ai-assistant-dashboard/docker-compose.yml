version: '3.8'

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ai-assistant-backend
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - DATABASE_URL=postgresql+asyncpg://postgres:password@postgres:5432/ai_assistant
      - REDIS_URL=redis://redis:6379
      - PYTHONUNBUFFERED=1
    volumes:
      - ./backend:/app
      - ./generated_images:/app/generated_images
      - ./uploads:/app/uploads
    depends_on:
      - postgres
      - redis
      - ollama
    networks:
      - ai-assistant-network
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: ai-assistant-frontend
    ports:
      - "3000:3000"
    environment:
      - VITE_API_URL=http://localhost:8000
      - VITE_WS_URL=ws://localhost:8000
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    networks:
      - ai-assistant-network
    restart: unless-stopped

  postgres:
    image: postgres:16-alpine
    container_name: ai-assistant-db
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=ai_assistant
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - ai-assistant-network
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: ai-assistant-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - ai-assistant-network
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: ai-assistant-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    networks:
      - ai-assistant-network
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  nginx:
    image: nginx:alpine
    container_name: ai-assistant-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - backend
      - frontend
    networks:
      - ai-assistant-network
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  ollama_data:

networks:
  ai-assistant-network:
    driver: bridge